import { NextRequest, NextResponse } from 'next/server';
import pdfParse from 'pdf-parse';
import { collection, addDoc, serverTimestamp } from 'firebase/firestore';
import { db } from '@/firebase/firestore';
import { TokenMiddleware, TokenEstimator } from '@/middleware/token.middleware';
import { MultiProviderService } from '@/services/multi-provider.service';

// üöÄ CONFIGURA√á√ïES OTIMIZADAS PARA MULTI-PROVIDER (14K TPM TOTAL)
const CHUNK_CONFIG = {
    MAX_TOKENS_PER_CHUNK: 3000,    // ‚úÖ Mantido para compatibilidade
    OVERLAP_TOKENS: 300,           // ‚úÖ Overlap inteligente
    MAX_CHUNKS: 35,                // ‚úÖ Aumentado devido √† maior capacidade TPM
    // DELAY_BETWEEN_CHUNKS removido - agora gerenciado pelo MultiProviderService
};

// Tipos de an√°lise dispon√≠veis
const ANALYSIS_TYPES = {
    'resumo': 'Resumo Executivo',
    'timeline': 'Cronologia do Processo',
    'partes': 'Identifica√ß√£o das Partes',
    'decisoes': 'Decis√µes Principais',
    'estrategia': 'An√°lise Estrat√©gica',
    'completa': 'An√°lise Completa'
};

// üöÄ LIMITES OTIMIZADOS
const ANALYSIS_LIMITS = {
    'resumo': { responseTokens: 600 },
    'timeline': { responseTokens: 800 },
    'partes': { responseTokens: 500 },
    'decisoes': { responseTokens: 1000 },
    'estrategia': { responseTokens: 1200 },
    'completa': { responseTokens: 2000 }
};

interface PdfAnalysisData {
    clientId: string;
    resposta: string;
    sucesso: boolean;
    metadata: {
        documentId: string;
        fileName: string;
        analysisType: string;
        modelo: string;
        timestamp: string;
        fileSize: number;
        textLength: number;
        chunksProcessed?: number;
        totalTokensUsed?: number;
        processingTimeMinutes?: number;
    };
}

interface TextChunk {
    index: number;
    text: string;
    tokenCount: number;
    startPosition: number;
    endPosition: number;
}

/**
 * Salva os dados da an√°lise de PDF no Firestore.
 */
async function saveAnalysisToFirestore(data: Omit<PdfAnalysisData, 'metadata'> & { metadata: Omit<PdfAnalysisData['metadata'], 'documentId'> }): Promise<string> {
    try {
        const docRef = await addDoc(collection(db, 'pdf_analysis'), {
            ...data,
            timestamp: serverTimestamp()
        });
        console.log("‚úÖ Documento salvo com ID:", docRef.id);
        return docRef.id;
    } catch (e) {
        console.error("‚ùå Erro ao salvar documento:", e);
        throw new Error('Erro ao salvar os dados da an√°lise no Firestore.');
    }
}

// Fun√ß√£o para processar o buffer do arquivo PDF
async function processPdfBuffer(buffer: Buffer): Promise<string> {
    try {
        const data = await pdfParse(buffer);
        return data.text;
    } catch (error) {
        console.error('‚ùå Erro ao processar PDF:', error);
        throw new Error('Erro ao extrair texto do PDF');
    }
}

// üöÄ FUN√á√ÉO OTIMIZADA: Divis√£o em chunks respeitando nova capacidade
function splitTextIntoChunks(text: string): TextChunk[] {
    const chunks: TextChunk[] = [];
    const totalTokens = TokenEstimator.estimateTokens(text);
    
    console.log(`üìÑ Texto total: ${text.length} caracteres, ~${totalTokens} tokens`);
    
    // Se o texto √© pequeno, retorna como chunk √∫nico
    if (totalTokens <= CHUNK_CONFIG.MAX_TOKENS_PER_CHUNK) {
        console.log('üìÑ Documento pequeno - processamento direto');
        return [{
            index: 0,
            text: text,
            tokenCount: totalTokens,
            startPosition: 0,
            endPosition: text.length
        }];
    }

    // üöÄ DIVIS√ÉO INTELIGENTE OTIMIZADA
    // Primeiro tenta dividir por se√ß√µes jur√≠dicas
    let sections = text.split(/(?=\n(?:PETI√á√ÉO|DESPACHO|DECIS√ÉO|SENTEN√áA|AC√ìRD√ÉO|PARECER|MANIFESTA√á√ÉO|CONTESTA√á√ÉO|RECURSO|INICIAL))/gi);
    
    // Se n√£o encontrou se√ß√µes, divide por par√°grafos
    if (sections.length === 1) {
        sections = text.split(/\n\s*\n/);
    }
    
    // Se ainda n√£o dividiu bem, for√ßa divis√£o por caracteres
    if (sections.length === 1) {
        const charsPerChunk = Math.ceil(text.length / Math.ceil(totalTokens / CHUNK_CONFIG.MAX_TOKENS_PER_CHUNK));
        sections = [];
        for (let i = 0; i < text.length; i += charsPerChunk) {
            sections.push(text.slice(i, i + charsPerChunk));
        }
    }

    let currentChunk = '';
    let currentTokens = 0;
    let chunkIndex = 0;
    let startPos = 0;

    for (let i = 0; i < sections.length; i++) {
        const section = sections[i];
        const sectionTokens = TokenEstimator.estimateTokens(section);
        
        // Se adicionar esta se√ß√£o ultrapassar o limite, finaliza o chunk atual
        if (currentTokens + sectionTokens > CHUNK_CONFIG.MAX_TOKENS_PER_CHUNK && currentChunk.length > 0) {
            chunks.push({
                index: chunkIndex,
                text: currentChunk.trim(),
                tokenCount: currentTokens,
                startPosition: startPos,
                endPosition: startPos + currentChunk.length
            });
            
            chunkIndex++;
            
            // Inicia novo chunk com overlap reduzido mas inteligente
            const sentences = currentChunk.split(/[.!?]+/);
            const overlapSentences = sentences.slice(-2).join('. '); // √öltimas 2 frases
            const overlapText = overlapSentences.length > CHUNK_CONFIG.OVERLAP_TOKENS ? 
                currentChunk.slice(-CHUNK_CONFIG.OVERLAP_TOKENS) : overlapSentences;
            
            currentChunk = overlapText + '\n' + section;
            currentTokens = TokenEstimator.estimateTokens(currentChunk);
            startPos = startPos + currentChunk.length - overlapText.length;
        } else {
            currentChunk += (currentChunk ? '\n' : '') + section;
            currentTokens = TokenEstimator.estimateTokens(currentChunk);
        }
        
        // Limite de seguran√ßa de chunks
        if (chunkIndex >= CHUNK_CONFIG.MAX_CHUNKS) {
            console.warn(`‚ö†Ô∏è Limite de ${CHUNK_CONFIG.MAX_CHUNKS} chunks atingido`);
            break;
        }
    }
    
    // Adiciona o √∫ltimo chunk se houver conte√∫do
    if (currentChunk.trim().length > 0) {
        // Verifica√ß√£o final de seguran√ßa
        const finalTokens = TokenEstimator.estimateTokens(currentChunk);
        if (finalTokens > CHUNK_CONFIG.MAX_TOKENS_PER_CHUNK) {
            // Se ainda assim est√° muito grande, for√ßa divis√£o
            console.warn(`‚ö†Ô∏è Chunk final muito grande (${finalTokens} tokens). For√ßando divis√£o...`);
            const halfPoint = Math.floor(currentChunk.length / 2);
            const firstHalf = currentChunk.slice(0, halfPoint).trim();
            const secondHalf = currentChunk.slice(halfPoint).trim();
            
            if (firstHalf.length > 0) {
                chunks.push({
                    index: chunkIndex,
                    text: firstHalf,
                    tokenCount: TokenEstimator.estimateTokens(firstHalf),
                    startPosition: startPos,
                    endPosition: startPos + firstHalf.length
                });
                chunkIndex++;
            }
            
            if (secondHalf.length > 0) {
                chunks.push({
                    index: chunkIndex,
                    text: secondHalf,
                    tokenCount: TokenEstimator.estimateTokens(secondHalf),
                    startPosition: startPos + firstHalf.length,
                    endPosition: startPos + currentChunk.length
                });
            }
        } else {
            chunks.push({
                index: chunkIndex,
                text: currentChunk.trim(),
                tokenCount: finalTokens,
                startPosition: startPos,
                endPosition: startPos + currentChunk.length
            });
        }
    }
    
    console.log(`üì¶ Texto dividido em ${chunks.length} chunks:`);
    chunks.forEach((chunk, i) => {
        console.log(`   Chunk ${i + 1}: ~${chunk.tokenCount} tokens`);
    });
    
    return chunks;
}

// üöÄ FUN√á√ÉO OTIMIZADA: Prompts concisos e diretos
function createOptimizedPrompt(chunk: TextChunk, analysisType: string, totalChunks: number): { systemPrompt: string; userPrompt: string } {
    // Sistema prompt conciso
    const systemPrompt = `Assistente jur√≠dico especializado. Chunk ${chunk.index + 1}/${totalChunks}.${totalChunks > 1 ? ' Esta √© uma an√°lise PARCIAL.' : ''}`;

    let userPrompt = '';

    switch (analysisType) {
        case 'resumo':
            userPrompt = `Resuma esta se√ß√£o do processo:\n\n${chunk.text}\n\nForne√ßa:\n1. Conte√∫do principal\n2. Informa√ß√µes relevantes\n3. Contexto processual`;
            break;

        case 'timeline':
            userPrompt = `Extraia cronologia desta se√ß√£o:\n\n${chunk.text}\n\nIdentifique:\n1. Datas e prazos\n2. Eventos processuais\n3. Marcos temporais\n\nOrdem cronol√≥gica.`;
            break;

        case 'partes':
            userPrompt = `Identifique partes nesta se√ß√£o:\n\n${chunk.text}\n\nExtraia:\n1. Pessoas/empresas\n2. Advogados\n3. √ìrg√£os\n4. Qualifica√ß√µes`;
            break;

        case 'decisoes':
            userPrompt = `Extraia decis√µes desta se√ß√£o:\n\n${chunk.text}\n\nIdentifique:\n1. Decis√µes/despachos\n2. Senten√ßas\n3. Fundamentos\n4. Impactos`;
            break;

        case 'estrategia':
            userPrompt = `An√°lise estrat√©gica desta se√ß√£o:\n\n${chunk.text}\n\nAnalise:\n1. Argumentos\n2. Pontos favor√°veis\n3. Fragilidades\n4. Elementos estrat√©gicos`;
            break;

        case 'completa':
            userPrompt = `An√°lise completa desta se√ß√£o:\n\n${chunk.text}\n\nForne√ßa:\n1. Resumo principal\n2. Aspectos jur√≠dicos\n3. Informa√ß√µes relevantes\n4. Elementos importantes`;
            break;

        default:
            userPrompt = `Analise esta se√ß√£o do processo:\n\n${chunk.text}`;
    }

    return { systemPrompt, userPrompt };
}

// üöÄ FUN√á√ÉO COM MULTI-PROVIDER SERVICE E MELHOR TRATAMENTO DE ERROS
async function analyzeChunkWithGroq(chunk: TextChunk, analysisType: string, totalChunks: number): Promise<string> {
    const { systemPrompt, userPrompt } = createOptimizedPrompt(chunk, analysisType, totalChunks);
    
    // Estima tokens do request completo
    const estimatedTokens = TokenEstimator.estimateTokens(systemPrompt + userPrompt) + 
                           (ANALYSIS_LIMITS[analysisType as keyof typeof ANALYSIS_LIMITS]?.responseTokens || 800);

    const requestBody = {
        messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt }
        ],
        temperature: 0.3,
        max_tokens: ANALYSIS_LIMITS[analysisType as keyof typeof ANALYSIS_LIMITS]?.responseTokens || 800,
        top_p: 0.9,
        stream: false
    };

    try {
        console.log(`üîÑ Processando chunk ${chunk.index + 1}/${totalChunks} (~${estimatedTokens} tokens estimados)`);
        
        // üöÄ USAR MULTI-PROVIDER SERVICE
        const response = await MultiProviderService.makeRequest(
            requestBody, 
            estimatedTokens,
            analysisType // Passa o tipo para sele√ß√£o inteligente de provider
        );

        if (response.ok) {
            const data = await response.json();
            const result = data.choices?.[0]?.message?.content || `Erro ao processar chunk ${chunk.index + 1}`;
            console.log(`‚úÖ Chunk ${chunk.index + 1} processado com sucesso`);
            return result;
        }

        throw new Error(`HTTP ${response.status}: ${response.statusText}`);

    } catch (error) {
        console.error(`‚ùå Erro no chunk ${chunk.index + 1}:`, error);
        
        // üîç IDENTIFICAR TIPO DE ERRO PARA RETRY INTELIGENTE
        const errorMessage = error instanceof Error ? error.message : String(error);
        
        // Erros que podem ser resolvidos com retry
        const retryableErrors = [
            'Nenhum provider dispon√≠vel no momento',
            'Rate limit exceeded',
            'Service temporarily unavailable',
            'Too many requests',
            'HTTP 429',
            'HTTP 503',
            'HTTP 502'
        ];
        
        const isRetryable = retryableErrors.some(retryableError => 
            errorMessage.toLowerCase().includes(retryableError.toLowerCase())
        );
        
        if (isRetryable) {
            // Marcar erro como tempor√°rio para retry
            const retryError = new Error(`RETRYABLE: ${errorMessage}`);//eslint-disable-next-line
            (retryError as any).retryable = true;
            throw retryError;
        } else {
            // Erro permanente - n√£o vale a pena retry
            throw new Error(`PERMANENT: ${errorMessage}`);
        }
    }
}

// üöÄ CONSOLIDA√á√ÉO INTELIGENTE COM TRATAMENTO DE SE√á√ïES FALTANTES
async function consolidateAnalysis(chunkAnalyses: string[], analysisType: string, fileName: string): Promise<string> {
    if (chunkAnalyses.length === 1) {
        return chunkAnalyses[0];
    }

    // üîç VERIFICAR SE√á√ïES FALTANTES OU COM ERRO
    const missingOrErrorSections: number[] = [];
    const validSections: number[] = [];
    
    chunkAnalyses.forEach((analysis, i) => {
        if (!analysis || 
            analysis.includes('[SE√á√ÉO') || 
            analysis.includes('[Erro ao processar') || 
            analysis.includes('INDISPON√çVEL') ||
            analysis.includes('N√ÉO PROCESSADA')) {
            missingOrErrorSections.push(i + 1);
        } else {
            validSections.push(i + 1);
        }
    });

    const systemPrompt = `Consolidador jur√≠dico especializado. Integre ${chunkAnalyses.length} an√°lises parciais em an√°lise √∫nica e coerente.${
        missingOrErrorSections.length > 0 ? 
        ` IMPORTANTE: As se√ß√µes ${missingOrErrorSections.join(', ')} n√£o est√£o dispon√≠veis devido a problemas t√©cnicos. Consolide apenas as se√ß√µes dispon√≠veis (${validSections.join(', ')}) e mencione claramente quais se√ß√µes faltam.` : ''
    }`;

    let userPrompt = `Consolide estas an√°lises em uma √∫nica an√°lise estruturada:\n\n`;
    
    chunkAnalyses.forEach((analysis, i) => {
        if (analysis && !analysis.includes('[SE√á√ÉO') && !analysis.includes('[Erro ao processar')) {
            userPrompt += `=== SE√á√ÉO ${i + 1} ===\n${analysis}\n\n`;
        } else {
            userPrompt += `=== SE√á√ÉO ${i + 1} - INDISPON√çVEL ===\n${analysis || '[Se√ß√£o n√£o processada]'}\n\n`;
        }
    });

    const analysisTypeText = ANALYSIS_TYPES[analysisType as keyof typeof ANALYSIS_TYPES];
    
    if (missingOrErrorSections.length > 0) {
        userPrompt += `\nCrie ${analysisTypeText} consolidado das se√ß√µes dispon√≠veis. OBRIGAT√ìRIO: Informe no in√≠cio da resposta que as se√ß√µes ${missingOrErrorSections.join(', ')} n√£o puderam ser processadas devido a sobrecarga tempor√°ria do sistema, mas que a an√°lise das demais se√ß√µes est√° completa.`;
    } else {
        userPrompt += `\nCrie ${analysisTypeText} consolidado eliminando redund√¢ncias e organizando logicamente.`;
    }

    // Estima tokens
    const estimatedTokens = TokenEstimator.estimateTokens(systemPrompt + userPrompt) + 
                           ((ANALYSIS_LIMITS[analysisType as keyof typeof ANALYSIS_LIMITS]?.responseTokens || 800) + 500);

    const requestBody = {
        messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt }
        ],
        temperature: 0.2,
        max_tokens: (ANALYSIS_LIMITS[analysisType as keyof typeof ANALYSIS_LIMITS]?.responseTokens || 800) + 500,
        top_p: 0.8,
        stream: false
    };

    try {
        console.log('üîÑ Consolidando an√°lises com MultiProviderService...');
        
        // üöÄ USAR MULTI-PROVIDER SERVICE PARA CONSOLIDA√á√ÉO
        const response = await MultiProviderService.makeRequest(
            requestBody, 
            estimatedTokens,
            analysisType
        );

        if (!response.ok) {
            throw new Error(`Erro na consolida√ß√£o: ${response.statusText}`);
        }

        const data = await response.json();
        const consolidatedResult = data.choices?.[0]?.message?.content || 'Erro ao consolidar an√°lises';
        
        // üîç ADICIONAR INFORMA√á√ïES T√âCNICAS SE HOUVER SE√á√ïES FALTANTES
        if (missingOrErrorSections.length > 0) {
            const technicalNote = `\n\n---\n**NOTA T√âCNICA:** Durante o processamento deste documento, ${missingOrErrorSections.length} de ${chunkAnalyses.length} se√ß√µes n√£o puderam ser analisadas devido √† sobrecarga tempor√°ria do sistema. A an√°lise apresentada est√° baseada nas se√ß√µes ${validSections.join(', ')} que foram processadas com sucesso. Para uma an√°lise completa, recomenda-se reprocessar o documento em alguns minutos.`;
            return consolidatedResult + technicalNote;
        }
        
        return consolidatedResult;
        
    } catch (error) {
        console.error('‚ùå Erro na consolida√ß√£o:', error);
        
        // üö® FALLBACK: Se a consolida√ß√£o falhar, retornar an√°lises separadas
        if (validSections.length > 0) {
            console.log('üîÑ Fallback: Retornando an√°lises n√£o consolidadas devido a erro na consolida√ß√£o...');
            
            let fallbackResult = `**AN√ÅLISE ${analysisTypeText.toUpperCase()} - DOCUMENTO: ${fileName}**\n\n`;
            
            if (missingOrErrorSections.length > 0) {
                fallbackResult += `‚ö†Ô∏è **AVISO:** As se√ß√µes ${missingOrErrorSections.join(', ')} n√£o puderam ser processadas devido a problemas t√©cnicos tempor√°rios.\n\n`;
            }
            
            chunkAnalyses.forEach((analysis, i) => {
                if (analysis && !analysis.includes('[SE√á√ÉO') && !analysis.includes('[Erro ao processar')) {
                    fallbackResult += `## SE√á√ÉO ${i + 1}\n\n${analysis}\n\n---\n\n`;
                }
            });
            
            return fallbackResult;
        }
        
        throw new Error(`Erro ao consolidar an√°lises: ${error}`);
    }
}

// üöÄ FUN√á√ÉO PRINCIPAL COM MULTI-PROVIDER E SISTEMA DE RETRY
async function analyzeWithGroq(text: string, analysisType: string, fileName: string): Promise<{analysis: string, chunksProcessed: number, totalTokensUsed: number, processingTimeMinutes: number}> {
    const startTime = Date.now();
    const chunks = splitTextIntoChunks(text);
    
    // Log da capacidade atual do sistema
    const capacity = MultiProviderService.getTotalCapacity();
    console.log(`üöÄ Capacidade MultiProvider: ${capacity.availableTPM}/${capacity.totalTPM} TPM dispon√≠veis`);
    console.log(`üöÄ Providers ativos: ${capacity.activeProviders}`);
    
    if (chunks.length === 1) {
        console.log('üìÑ Documento pequeno - processamento direto');
        const analysis = await analyzeChunkWithGroq(chunks[0], analysisType, 1);
        const promptTokens = TokenEstimator.estimateTokens(text);
        const responseTokens = TokenEstimator.estimateTokens(analysis);
        const processingTime = (Date.now() - startTime) / 60000;
        
        return {
            analysis,
            chunksProcessed: 1,
            totalTokensUsed: promptTokens + responseTokens,
            processingTimeMinutes: processingTime
        };
    }
    
    // Processamento com m√∫ltiplos chunks usando MultiProvider
    console.log(`üì¶ Processando ${chunks.length} chunks com MultiProviderService...`);
    console.log(`‚è∞ Processamento paralelo inteligente ativado`);
    
    const chunkAnalyses: string[] = [];
    let totalTokensUsed = 0;
    const failedChunks: number[] = []; // Track de chunks que falharam
    
    // üîÑ PRIMEIRA PASSADA: Tentar processar todos os chunks
    for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        console.log(`üîÑ Processando chunk ${i + 1}/${chunks.length} (~${chunk.tokenCount} tokens)...`);
        
        try {
            const chunkAnalysis = await analyzeChunkWithGroq(chunk, analysisType, chunks.length);
            chunkAnalyses[i] = chunkAnalysis;
            
            // Calcular tokens usados neste chunk
            const chunkTokens = chunk.tokenCount + TokenEstimator.estimateTokens(chunkAnalysis);
            totalTokensUsed += chunkTokens;
            
            console.log(`‚úÖ Chunk ${i + 1} conclu√≠do - ${chunkTokens} tokens usados`);
            
        } catch (error) {
            console.error(`‚ùå Erro no chunk ${i + 1}:`, error);
            failedChunks.push(i);
            chunkAnalyses[i] = 'Erro ao processar chunk'; // Marca como falhou
        }
    }
    
    // üîÑ SISTEMA DE RETRY: Tentar novamente os chunks que falharam
    if (failedChunks.length > 0) {
        console.log(`üîÑ Iniciando retry para ${failedChunks.length} chunks que falharam...`);
        
        const retryConfig = {
            maxRetries: 3,
            baseDelay: 5000, // 5 segundos
            backoffMultiplier: 2
        };
        
        for (const chunkIndex of failedChunks) {
            const chunk = chunks[chunkIndex];
            let retryCount = 0;
            let success = false;
            
            while (retryCount < retryConfig.maxRetries && !success) {
                const delay = retryConfig.baseDelay * Math.pow(retryConfig.backoffMultiplier, retryCount);
                
                console.log(`üîÑ Retry ${retryCount + 1}/${retryConfig.maxRetries} para chunk ${chunkIndex + 1} em ${delay/1000}s...`);
                
                // Aguardar antes do retry
                await new Promise(resolve => setTimeout(resolve, delay));
                
                // Verificar se h√° providers dispon√≠veis antes de tentar
                const currentCapacity = MultiProviderService.getTotalCapacity();
                if (currentCapacity.availableTPM === 0) {
                    console.log(`‚è≥ Aguardando providers ficarem dispon√≠veis...`);
                    await new Promise(resolve => setTimeout(resolve, 10000)); // Espera mais 10s
                    continue;
                }
                
                try {
                    console.log(`üîÑ Tentativa ${retryCount + 1}: Processando chunk ${chunkIndex + 1}...`);
                    const chunkAnalysis = await analyzeChunkWithGroq(chunk, analysisType, chunks.length);
                    chunkAnalyses[chunkIndex] = chunkAnalysis;
                    
                    const chunkTokens = chunk.tokenCount + TokenEstimator.estimateTokens(chunkAnalysis);
                    totalTokensUsed += chunkTokens;
                    
                    console.log(`‚úÖ Chunk ${chunkIndex + 1} recuperado com sucesso no retry ${retryCount + 1} - ${chunkTokens} tokens usados`);
                    success = true;
                    
                    // Remove da lista de falhados
                    const indexToRemove = failedChunks.indexOf(chunkIndex);
                    if (indexToRemove > -1) {
                        failedChunks.splice(indexToRemove, 1);
                    }
                    
                } catch (error) {
                    retryCount++;
                    console.error(`‚ùå Retry ${retryCount} falhou para chunk ${chunkIndex + 1}:`, error);
                    
                    if (retryCount >= retryConfig.maxRetries) {
                        console.error(`üí• Chunk ${chunkIndex + 1} falhou definitivamente ap√≥s ${retryConfig.maxRetries} tentativas`);
                    }
                }
            }
        }
    }
    
    // üîÑ VERIFICA√á√ÉO FINAL: Verificar se ainda h√° chunks cr√≠ticos que falharam
    const finalFailedChunks = failedChunks.filter(i => chunkAnalyses[i] === null);
    
    if (finalFailedChunks.length > 0) {
        console.warn(`‚ö†Ô∏è ${finalFailedChunks.length} chunks n√£o puderam ser processados ap√≥s tentativas de retry`);
        
        // Se mais de 50% dos chunks falharam, abortar an√°lise
        if (finalFailedChunks.length > chunks.length * 0.5) {
            throw new Error(`Falha cr√≠tica: ${finalFailedChunks.length}/${chunks.length} chunks n√£o puderam ser processados. Sistema temporariamente sobrecarregado.`);
        }
        
        // Para chunks que ainda falharam, tentar uma abordagem alternativa
        for (const chunkIndex of finalFailedChunks) {
            const chunk = chunks[chunkIndex];
            
            // Se o chunk for muito grande, tentar dividir ao meio
            if (chunk.tokenCount > 3000) {
                console.log(`üîÄ Tentando dividir chunk ${chunkIndex + 1} grande (${chunk.tokenCount} tokens) ao meio...`);
                
                try {
                    const halfPoint = Math.floor(chunk.text.length / 2);
                    const firstHalf = chunk.text.slice(0, halfPoint).trim();
                    const secondHalf = chunk.text.slice(halfPoint).trim();
                    
                    const halfChunk1 = {
                        ...chunk,
                        text: firstHalf,
                        tokenCount: TokenEstimator.estimateTokens(firstHalf)
                    };
                    
                    const halfChunk2 = {
                        ...chunk,
                        text: secondHalf,
                        tokenCount: TokenEstimator.estimateTokens(secondHalf)
                    };
                    
                    // Tentar processar as metades
                    const analysis1 = await analyzeChunkWithGroq(halfChunk1, analysisType, chunks.length);
                    const analysis2 = await analyzeChunkWithGroq(halfChunk2, analysisType, chunks.length);
                    
                    chunkAnalyses[chunkIndex] = `${analysis1}\n\n${analysis2}`;
                    
                    const combinedTokens = halfChunk1.tokenCount + halfChunk2.tokenCount + 
                                         TokenEstimator.estimateTokens(analysis1) + 
                                         TokenEstimator.estimateTokens(analysis2);
                    totalTokensUsed += combinedTokens;
                    
                    console.log(`‚úÖ Chunk ${chunkIndex + 1} processado atrav√©s de divis√£o - ${combinedTokens} tokens usados`);
                    
                } catch (splitError) {
                    console.error(`‚ùå Falha ao dividir chunk ${chunkIndex + 1}:`, splitError);
                    chunkAnalyses[chunkIndex] = `[SE√á√ÉO ${chunkIndex + 1} INDISPON√çVEL: Esta se√ß√£o n√£o p√¥de ser processada devido a sobrecarga tempor√°ria do sistema. Conte√∫do aproximado: ${chunk.text.slice(0, 200)}...]`;
                }
            } else {
                // Para chunks menores que ainda falharam, usar mensagem informativa
                chunkAnalyses[chunkIndex] = `[SE√á√ÉO ${chunkIndex + 1} INDISPON√çVEL: Esta se√ß√£o n√£o p√¥de ser processada devido a sobrecarga tempor√°ria do sistema. Conte√∫do aproximado: ${chunk.text.slice(0, 200)}...]`;
            }
        }
    }
    
    // Garantir que n√£o h√° valores null no array
    for (let i = 0; i < chunkAnalyses.length; i++) {
        if (chunkAnalyses[i] === null || chunkAnalyses[i] === undefined) {
            chunkAnalyses[i] = `[SE√á√ÉO ${i + 1} N√ÉO PROCESSADA: Conte√∫do indispon√≠vel devido a erro t√©cnico]`;
        }
    }
    
    console.log('üîÑ Consolidando an√°lises...');
    const consolidatedAnalysis = await consolidateAnalysis(chunkAnalyses, analysisType, fileName);
    const consolidationTokens = TokenEstimator.estimateTokens(consolidatedAnalysis);
    totalTokensUsed += consolidationTokens;
    
    const processingTime = (Date.now() - startTime) / 60000;
    console.log(`‚úÖ An√°lise conclu√≠da - Total: ${totalTokensUsed} tokens em ${processingTime.toFixed(1)} minutos`);
    
    // Log final das estat√≠sticas dos providers
    const finalStats = MultiProviderService.getProviderStats();
    console.log('üìä Estat√≠sticas finais dos providers:', Object.keys(finalStats).map(key => ({
        provider: key,
        usage: finalStats[key].capacityUsed
    })));
    
    const successfulChunks = chunkAnalyses.filter(analysis => 
        analysis && !analysis.includes('[SE√á√ÉO') && !analysis.includes('[Erro ao processar')
    ).length;
    
    console.log(`üìà Resultado final: ${successfulChunks}/${chunks.length} chunks processados com sucesso`);
    
    return {
        analysis: consolidatedAnalysis,
        chunksProcessed: chunks.length,
        totalTokensUsed,
        processingTimeMinutes: processingTime
    };
}

export async function POST(request: NextRequest) {
    try {
        // Verificar se o MultiProviderService est√° configurado
        const capacity = MultiProviderService.getTotalCapacity();
        if (capacity.activeProviders === 0) {
            console.error('‚ùå Nenhum provider ativo no MultiProviderService');
            return NextResponse.json(
                {
                    error: 'Servi√ßo temporariamente indispon√≠vel',
                    resposta: 'Sistema de an√°lise temporariamente indispon√≠vel. Tente novamente em alguns minutos.',
                    sucesso: false
                },
                { status: 503 }
            );
        }

        console.log(`üöÄ Iniciando com ${capacity.activeProviders} providers ativos (${capacity.availableTPM}/${capacity.totalTPM} TPM dispon√≠veis)`);

        const formData = await request.formData();
        const file = formData.get('file') as File;
        const analysisType = formData.get('analysisType') as string || 'completa';
        const clientId = formData.get('clientId') as string;
        const advogadoId = formData.get('advogadoId') as string || clientId;

        // Valida√ß√µes b√°sicas
        if (!file) {
            return NextResponse.json(
                {
                    error: 'Arquivo n√£o fornecido',
                    resposta: 'Por favor, selecione um arquivo PDF para an√°lise.',
                    sucesso: false
                },
                { status: 400 }
            );
        }

        if (file.type !== 'application/pdf') {
            return NextResponse.json(
                {
                    error: 'Tipo de arquivo inv√°lido',
                    resposta: 'Apenas arquivos PDF s√£o aceitos.',
                    sucesso: false
                },
                { status: 400 }
            );
        }

        if (!advogadoId) {
            return NextResponse.json(
                {
                    error: 'ID do advogado n√£o informado',
                    resposta: 'Identifica√ß√£o do usu√°rio √© necess√°ria para utilizar o servi√ßo.',
                    sucesso: false
                },
                { status: 400 }
            );
        }

        // üöÄ VALIDA√á√ÉO DE TAMANHO DE ARQUIVO
        const maxFileSizeBytes = 50 * 1024 * 1024; // 50MB
        if (file.size > maxFileSizeBytes) {
            return NextResponse.json(
                {
                    error: 'Arquivo muito grande',
                    resposta: 'O arquivo deve ter no m√°ximo 50MB para ser processado.',
                    sucesso: false
                },
                { status: 400 }
            );
        }

        // Verifica√ß√£o de tokens
        const tokenCheck = await TokenMiddleware.checkTokens(advogadoId, 'PDF_ANALYSIS');
        
        if (!tokenCheck.success) {
            console.log('‚ùå Limite de tokens excedido:', tokenCheck.error);
            
            let errorMessage = '';
            if (tokenCheck.error.code === 'SUBSCRIPTION_INACTIVE') {
                errorMessage = 'Servi√ßo de an√°lise temporariamente indispon√≠vel. Nossa equipe entrar√° em contato em breve.';
            } else if (tokenCheck.error.code === 'DAILY_LIMIT') {
                errorMessage = 'Limite di√°rio de an√°lises de PDF atingido. Tente novamente amanh√£.';
            } else if (tokenCheck.error.code === 'MINUTE_LIMIT') {
                errorMessage = 'Muitas an√°lises em pouco tempo. Aguarde alguns minutos e tente novamente.';
            } else {
                errorMessage = 'Servi√ßo de an√°lise temporariamente indispon√≠vel. Tente novamente mais tarde.';
            }

            const status = tokenCheck.error.code === 'SUBSCRIPTION_INACTIVE' ? 402 : 429;
            const response = NextResponse.json(
                {
                    error: tokenCheck.error.error,
                    resposta: errorMessage,
                    code: tokenCheck.error.code,
                    sucesso: false
                },
                { status }
            );

            if (tokenCheck.error.limits) {
                response.headers.set('X-RateLimit-Daily-Limit', tokenCheck.error.limits.dailyLimit.toString());
                response.headers.set('X-RateLimit-Daily-Remaining', Math.max(0, tokenCheck.error.limits.dailyLimit - tokenCheck.error.limits.dailyUsed).toString());
                response.headers.set('X-RateLimit-Minute-Limit', tokenCheck.error.limits.minuteLimit.toString());
                response.headers.set('X-RateLimit-Minute-Remaining', Math.max(0, tokenCheck.error.limits.minuteLimit - tokenCheck.error.limits.minuteUsed).toString());
            }
            
            if (tokenCheck.error.retryAfter) {
                response.headers.set('Retry-After', tokenCheck.error.retryAfter.toString());
            }

            return response;
        }
        
        // Processamento do arquivo
        const bytes = await file.arrayBuffer();
        const buffer = Buffer.from(bytes);

        try {
            console.log('üìÑ Extraindo texto do PDF...', {
                fileName: file.name,
                fileSize: `${Math.round(file.size / 1024)}KB`
            });
            
            const extractedText = await processPdfBuffer(buffer);

            if (!extractedText || extractedText.trim().length < 100) {
                return NextResponse.json(
                    {
                        error: 'PDF vazio ou ileg√≠vel',
                        resposta: 'O arquivo PDF n√£o cont√©m texto suficiente para an√°lise. Verifique se o arquivo n√£o est√° corrompido ou se √© uma imagem escaneada.',
                        sucesso: false
                    },
                    { status: 400 }
                );
            }

            console.log('üîÑ Iniciando an√°lise com MultiProviderService...', {
                fileName: file.name,
                fileSize: file.size,
                textLength: extractedText.length,
                analysisType,
                advogadoId
            });
            
            // üöÄ AN√ÅLISE COM MULTI-PROVIDER SERVICE
            const result = await analyzeWithGroq(extractedText, analysisType, file.name);

            console.log('üíæ Salvando an√°lise no Firestore...');
            const metadata = {
                fileName: file.name,
                analysisType: ANALYSIS_TYPES[analysisType as keyof typeof ANALYSIS_TYPES],
                modelo: 'MultiProvider (Groq)',
                timestamp: new Date().toISOString(),
                fileSize: file.size,
                textLength: extractedText.length,
                chunksProcessed: result.chunksProcessed,
                totalTokensUsed: result.totalTokensUsed,
                processingTimeMinutes: result.processingTimeMinutes
            };
            
            const analysisData = {
                clientId,
                resposta: result.analysis,
                sucesso: true,
                metadata
            };

            const documentId = await saveAnalysisToFirestore(analysisData);

            // Registro de tokens
            try {
                await TokenMiddleware.incrementTokens(advogadoId, result.totalTokensUsed);
                
                console.log('‚úÖ An√°lise conclu√≠da com sucesso:', {
                    advogadoId,
                    fileName: file.name,
                    analysisType,
                    chunksProcessed: result.chunksProcessed,
                    totalTokensUsed: result.totalTokensUsed,
                    processingTimeMinutes: result.processingTimeMinutes.toFixed(1),
                    documentId
                });
            } catch (tokenError) {
                console.error('‚ùå Erro ao registrar tokens:', tokenError);
                
                // üöÄ NOVO: Verificar se √© acesso irrestrito
                const errorMessage = tokenError instanceof Error ? tokenError.message : String(tokenError);
                if (errorMessage.includes('acesso irrestrito')) {
                    console.log(`üîì Tokens n√£o incrementados - ${errorMessage}`);
                }
            }

            return NextResponse.json({
                resposta: result.analysis,
                sucesso: true,
                metadata: {
                    ...metadata,
                    documentId,
                    fileUrl: `api/pdf-analysis/${documentId}`
                }
            });

        } catch (error) {
            console.error('‚ùå Erro no processamento da an√°lise:', error);
            const errorMessage = error instanceof Error ? error.message : 'Erro desconhecido.';
            return NextResponse.json(
                {
                    error: 'Erro no processamento da an√°lise.',
                    resposta: errorMessage,
                    sucesso: false
                },
                { status: 500 }
            );
        }

    } catch (error) {
        console.error('‚ùå Erro geral no endpoint /api/pdf-analysis:', error);
        return NextResponse.json(
            {
                error: 'Erro interno do servidor',
                resposta: 'Desculpe, ocorreu um erro ao processar o arquivo. Tente novamente mais tarde.',
                sucesso: false
            },
            { status: 500 }
        );
    }
}