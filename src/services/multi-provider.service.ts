// src/services/multi-provider.service.ts
/**
 * üöÄ MULTI-PROVIDER SERVICE PARA GROQ API
 * 
 * Sistema de balanceamento inteligente entre m√∫ltiplos modelos Groq
 * para aumentar capacidade de TPM sem custos adicionais.
 * 
 * Capacidade Total: 14k TPM (6k + 8k)
 * Suporte: 5-8 usu√°rios simult√¢neos
 */

interface GroqModel {
    name: string;
    tpmLimit: number;
    rpmLimit: number;
    quality: 'high' | 'medium';
    preferredFor: string[];
  }
  
  interface ProviderMetrics {
    requestsInCurrentMinute: number;
    tokensInCurrentMinute: number;
    lastRequestTime: number;
    minuteWindowStart: number;
    totalRequests: number;
    totalTokens: number;
    errorCount: number;
    averageResponseTime: number;
  }
  
  interface ProviderStatus {
    isAvailable: boolean;
    nextAvailableTime: number;
    currentLoad: number; // 0-1 (percentage)
    consecutiveErrors: number;
  }
  
  export class MultiProviderService {
    // üöÄ CONFIGURA√á√ÉO DOS MODELOS GROQ
    private static readonly MODELS: Record<string, GroqModel> = {
      'llama-3.1-8b-instant': {
        name: 'llama-3.1-8b-instant',
        tpmLimit: 6000,
        rpmLimit: 30,
        quality: 'high',
        preferredFor: ['resumo', 'timeline', 'partes']
      },
      'openai/gpt-oss-120b': {
        name: 'openai/gpt-oss-120b',
        tpmLimit: 8000,
        rpmLimit: 30,
        quality: 'high',
        preferredFor: ['decisoes', 'estrategia', 'completa']
      }
    };
  
    // üöÄ CONFIGURA√á√ïES GLOBAIS
    private static readonly CONFIG = {
      GROQ_API_URL: 'https://api.groq.com/openai/v1/chat/completions',
      MAX_RETRIES: 3,
      BASE_DELAY: 2000,
      MAX_DELAY: 30000,
      BACKOFF_MULTIPLIER: 2,
      ERROR_THRESHOLD: 5, // M√°ximo de erros consecutivos antes de desabilitar
      RECOVERY_TIME: 300000, // 5 minutos para tentar reativar provider com erro
      LOAD_BALANCE_STRATEGY: 'round_robin' as 'round_robin' | 'least_loaded' | 'preferred'
    };
  
    // üöÄ M√âTRICAS E STATUS POR PROVIDER
    private static metrics: Record<string, ProviderMetrics> = {};
    private static status: Record<string, ProviderStatus> = {};
    private static lastUsedProvider = 0; // Para round-robin
  
    // üöÄ INICIALIZA√á√ÉO DOS PROVIDERS
    static {
      Object.keys(this.MODELS).forEach(modelName => {
        this.metrics[modelName] = {
          requestsInCurrentMinute: 0,
          tokensInCurrentMinute: 0,
          lastRequestTime: 0,
          minuteWindowStart: Date.now(),
          totalRequests: 0,
          totalTokens: 0,
          errorCount: 0,
          averageResponseTime: 0
        };
        
        this.status[modelName] = {
          isAvailable: true,
          nextAvailableTime: 0,
          currentLoad: 0,
          consecutiveErrors: 0
        };
      });
    }
  
    /**
     * üöÄ M√âTODO PRINCIPAL: Faz request com balanceamento autom√°tico
     */
    static async makeRequest(//eslint-disable-next-line
      requestBody: any, 
      estimatedTokens: number,
      analysisType?: string
    ): Promise<Response> {
      const startTime = Date.now();
      
      // Atualizar m√©tricas de todos os providers
      this.updateAllMetrics();
      
      // Selecionar melhor provider
      const selectedModel = this.selectBestProvider(estimatedTokens, analysisType);
      
      if (!selectedModel) {
        throw new Error('Nenhum provider dispon√≠vel no momento. Tente novamente em alguns minutos.');
      }
  
      console.log(`üéØ Selecionado: ${selectedModel} para ${estimatedTokens} tokens`);
  
      // Aplicar rate limiting espec√≠fico do provider
      await this.enforceProviderRateLimit(selectedModel, estimatedTokens);
  
      // Fazer a requisi√ß√£o com retry
      const response = await this.makeRequestWithRetry(selectedModel, requestBody, estimatedTokens, startTime);
      
      // Atualizar m√©tricas de sucesso
      this.updateSuccessMetrics(selectedModel, estimatedTokens, startTime);
      
      return response;
    }
  
    /**
     * üß† SELE√á√ÉO INTELIGENTE DE PROVIDER
     */
    private static selectBestProvider(estimatedTokens: number, analysisType?: string): string | null {
      const availableModels = Object.keys(this.MODELS).filter(model => 
        this.isProviderAvailable(model, estimatedTokens)
      );
  
      if (availableModels.length === 0) {
        // Tentar recuperar providers com erro se j√° passou tempo suficiente
        this.attemptProviderRecovery();
        return null;
      }
  
      // Estrat√©gia de sele√ß√£o baseada na configura√ß√£o
      switch (this.CONFIG.LOAD_BALANCE_STRATEGY) {
        case 'preferred':
          return this.selectByPreference(availableModels, analysisType);
        
        case 'least_loaded':
          return this.selectLeastLoaded(availableModels);
        
        case 'round_robin':
        default:
          return this.selectRoundRobin(availableModels);
      }
    }
  
    /**
     * üéØ SELE√á√ÉO POR PREFER√äNCIA (baseado no tipo de an√°lise)
     */
    private static selectByPreference(availableModels: string[], analysisType?: string): string {
      if (!analysisType) {
        return this.selectRoundRobin(availableModels);
      }
  
      // Buscar modelo preferido para este tipo de an√°lise
      const preferredModel = availableModels.find(model => 
        this.MODELS[model].preferredFor.includes(analysisType)
      );
  
      if (preferredModel && this.status[preferredModel].currentLoad < 0.8) {
        return preferredModel;
      }
  
      // Fallback para least loaded
      return this.selectLeastLoaded(availableModels);
    }
  
    /**
     * ‚öñÔ∏è SELE√á√ÉO POR MENOR CARGA
     */
    private static selectLeastLoaded(availableModels: string[]): string {
      return availableModels.reduce((best, current) => {
        const currentLoad = this.status[current].currentLoad;
        const bestLoad = this.status[best].currentLoad;
        return currentLoad < bestLoad ? current : best;
      });
    }
  
    /**
     * üîÑ SELE√á√ÉO ROUND-ROBIN
     */
    private static selectRoundRobin(availableModels: string[]): string {
      this.lastUsedProvider = (this.lastUsedProvider + 1) % availableModels.length;
      return availableModels[this.lastUsedProvider];
    }
  
    /**
     * ‚úÖ VERIFICAR SE PROVIDER EST√Å DISPON√çVEL
     */
    private static isProviderAvailable(modelName: string, estimatedTokens: number): boolean {
      const status = this.status[modelName];
      const metrics = this.metrics[modelName];
      const model = this.MODELS[modelName];
  
      // Verificar se n√£o est√° em recupera√ß√£o
      if (!status.isAvailable && Date.now() < status.nextAvailableTime) {
        return false;
      }
  
      // Verificar limites de TPM
      if (metrics.tokensInCurrentMinute + estimatedTokens > model.tpmLimit) {
        return false;
      }
  
      // Verificar limites de RPM
      if (metrics.requestsInCurrentMinute >= model.rpmLimit) {
        return false;
      }
  
      return true;
    }
  
    /**
     * ‚è∞ APLICAR RATE LIMITING POR PROVIDER
     */
    private static async enforceProviderRateLimit(modelName: string, estimatedTokens: number): Promise<void> {
      const metrics = this.metrics[modelName];
      const model = this.MODELS[modelName];
      const now = Date.now();
  
      // Reset janela se passou 1 minuto
      if (now - metrics.minuteWindowStart > 60000) {
        metrics.requestsInCurrentMinute = 0;
        metrics.tokensInCurrentMinute = 0;
        metrics.minuteWindowStart = now;
      }
  
      // Calcular delay necess√°rio baseado no √∫ltimo request
      const timeSinceLastRequest = now - metrics.lastRequestTime;
      const minimumDelay = Math.max(0, 60000 / model.rpmLimit); // Espa√ßamento m√≠nimo entre requests
  
      if (timeSinceLastRequest < minimumDelay) {
        const delayNeeded = minimumDelay - timeSinceLastRequest;
        console.log(`‚è≥ Rate limiting ${modelName}: aguardando ${Math.round(delayNeeded/1000)}s`);
        await this.delay(delayNeeded);
      }
  
      // Atualizar m√©tricas antes do request
      metrics.requestsInCurrentMinute++;
      metrics.tokensInCurrentMinute += estimatedTokens;
      metrics.lastRequestTime = Date.now();
      
      // Atualizar carga atual (0-1)
      this.status[modelName].currentLoad = Math.max(
        metrics.tokensInCurrentMinute / model.tpmLimit,
        metrics.requestsInCurrentMinute / model.rpmLimit
      );
    }
  
    /**
     * üîÑ FAZER REQUEST COM RETRY E FALLBACK
     */
    private static async makeRequestWithRetry(
      modelName: string, //eslint-disable-next-line
      requestBody: any, 
      estimatedTokens: number,//eslint-disable-next-line
      startTime: number
    ): Promise<Response> {
      const apiKey = process.env.GROQ_API_KEY;
      if (!apiKey) {
        throw new Error('GROQ_API_KEY n√£o configurada');
      }
  
      // Preparar request body com o modelo espec√≠fico
      const finalRequestBody = {
        ...requestBody,
        model: modelName
      };
  
      let lastError: Error | null = null;
  
      for (let attempt = 1; attempt <= this.CONFIG.MAX_RETRIES; attempt++) {
        try {
          console.log(`üîÑ ${modelName} - Tentativa ${attempt}/${this.CONFIG.MAX_RETRIES}`);
          
          const response = await fetch(this.CONFIG.GROQ_API_URL, {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${apiKey}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify(finalRequestBody)
          });
  
          if (response.ok) {
            console.log(`‚úÖ ${modelName} - Sucesso na tentativa ${attempt}`);
            
            // Reset contador de erros consecutivos
            this.status[modelName].consecutiveErrors = 0;
            this.status[modelName].isAvailable = true;
            
            return response;
          }
  
          // Tratar diferentes tipos de erro
          if (response.status === 429) {
            const retryAfter = response.headers.get('Retry-After');
            const delay = retryAfter ? parseInt(retryAfter) * 1000 : 
                         Math.min(this.CONFIG.BASE_DELAY * Math.pow(this.CONFIG.BACKOFF_MULTIPLIER, attempt - 1), this.CONFIG.MAX_DELAY);
            
            console.log(`‚è≥ ${modelName} - Rate limit (429). Aguardando ${Math.round(delay/1000)}s...`);
            
            if (attempt === this.CONFIG.MAX_RETRIES) {
              // Se √© a √∫ltima tentativa, tentar outro provider
              return await this.fallbackToAnotherProvider(finalRequestBody, estimatedTokens, modelName);
            }
            
            await this.delay(delay);
            continue;
          }
  
          throw new Error(`HTTP ${response.status}: ${response.statusText}`);
  
        } catch (error) {
          lastError = error as Error;
          console.error(`‚ùå ${modelName} - Erro na tentativa ${attempt}:`, error);
          
          // Incrementar contador de erros
          this.updateErrorMetrics(modelName);
          
          if (attempt === this.CONFIG.MAX_RETRIES) {
            // √öltima tentativa - tentar outro provider
            try {
              return await this.fallbackToAnotherProvider(finalRequestBody, estimatedTokens, modelName);
            } catch (fallbackError) {
              console.error(`‚ùå Fallback tamb√©m falhou:`, fallbackError);
              throw lastError;
            }
          }
          
          // Backoff exponencial
          const delay = Math.min(
            this.CONFIG.BASE_DELAY * Math.pow(this.CONFIG.BACKOFF_MULTIPLIER, attempt - 1), 
            this.CONFIG.MAX_DELAY
          );
          console.log(`‚è≥ Aguardando ${Math.round(delay/1000)}s antes da pr√≥xima tentativa...`);
          await this.delay(delay);
        }
      }
  
      throw lastError || new Error('Falha completa ap√≥s todas as tentativas');
    }
  
    /**
     * üÜò FALLBACK PARA OUTRO PROVIDER
     */
    private static async fallbackToAnotherProvider(//eslint-disable-next-line
      requestBody: any, 
      estimatedTokens: number, 
      excludeModel: string
    ): Promise<Response> {
      console.log(`üÜò Tentando fallback - excluindo ${excludeModel}`);
      
      const availableModels = Object.keys(this.MODELS).filter(model => 
        model !== excludeModel && this.isProviderAvailable(model, estimatedTokens)
      );
  
      if (availableModels.length === 0) {
        throw new Error('Nenhum provider dispon√≠vel para fallback');
      }
  
      const fallbackModel = this.selectLeastLoaded(availableModels);
      console.log(`üîÑ Fallback para: ${fallbackModel}`);
      
      // Aplicar rate limiting do provider de fallback
      await this.enforceProviderRateLimit(fallbackModel, estimatedTokens);
      
      // Fazer request com o provider de fallback (sem retry - j√° √© um fallback)
      const apiKey = process.env.GROQ_API_KEY;
      const response = await fetch(this.CONFIG.GROQ_API_URL, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          ...requestBody,
          model: fallbackModel
        })
      });
  
      if (!response.ok) {
        throw new Error(`Fallback falhou: HTTP ${response.status}`);
      }
  
      // Atualizar m√©tricas do provider de fallback
      this.updateSuccessMetrics(fallbackModel, estimatedTokens, Date.now());
      
      return response;
    }
  
    /**
     * üìä ATUALIZAR M√âTRICAS DE SUCESSO
     */
    private static updateSuccessMetrics(modelName: string, tokensUsed: number, startTime: number): void {
      const metrics = this.metrics[modelName];
      const responseTime = Date.now() - startTime;
      
      metrics.totalRequests++;
      metrics.totalTokens += tokensUsed;
      
      // Calcular m√©dia m√≥vel do tempo de resposta
      const alpha = 0.1; // Fator de suaviza√ß√£o
      metrics.averageResponseTime = metrics.averageResponseTime === 0 ? 
        responseTime : 
        (alpha * responseTime) + ((1 - alpha) * metrics.averageResponseTime);
    }
  
    /**
     * ‚ùå ATUALIZAR M√âTRICAS DE ERRO
     */
    private static updateErrorMetrics(modelName: string): void {
      const status = this.status[modelName];
      const metrics = this.metrics[modelName];
      
      status.consecutiveErrors++;
      metrics.errorCount++;
      
      // Se muitos erros consecutivos, desabilitar temporariamente
      if (status.consecutiveErrors >= this.CONFIG.ERROR_THRESHOLD) {
        status.isAvailable = false;
        status.nextAvailableTime = Date.now() + this.CONFIG.RECOVERY_TIME;
        
        console.warn(`‚ö†Ô∏è Provider ${modelName} temporariamente desabilitado ap√≥s ${status.consecutiveErrors} erros consecutivos`);
      }
    }
  
    /**
     * üîÑ ATUALIZAR TODAS AS M√âTRICAS
     */
    private static updateAllMetrics(): void {
      const now = Date.now();
      
      Object.keys(this.MODELS).forEach(modelName => {
        const metrics = this.metrics[modelName];
        const status = this.status[modelName];
        
        // Reset janela se passou 1 minuto
        if (now - metrics.minuteWindowStart > 60000) {
          metrics.requestsInCurrentMinute = 0;
          metrics.tokensInCurrentMinute = 0;
          metrics.minuteWindowStart = now;
        }
        
        // Recalcular carga atual
        const model = this.MODELS[modelName];
        status.currentLoad = Math.max(
          metrics.tokensInCurrentMinute / model.tpmLimit,
          metrics.requestsInCurrentMinute / model.rpmLimit
        );
      });
    }
  
    /**
     * üîß TENTAR RECUPERAR PROVIDERS COM ERRO
     */
    private static attemptProviderRecovery(): void {
      const now = Date.now();
      
      Object.keys(this.MODELS).forEach(modelName => {
        const status = this.status[modelName];
        
        if (!status.isAvailable && now >= status.nextAvailableTime) {
          console.log(`üîß Tentando recuperar provider: ${modelName}`);
          status.isAvailable = true;
          status.consecutiveErrors = 0;
        }
      });
    }
  
    /**
     * ‚è∞ DELAY HELPER
     */
    private static delay(ms: number): Promise<void> {
      return new Promise(resolve => setTimeout(resolve, ms));
    }
  
    /**
     * üìà OBTER ESTAT√çSTICAS DOS PROVIDERS
     */
    static getProviderStats(): Record<string, {
      model: GroqModel;
      metrics: ProviderMetrics;
      status: ProviderStatus;
      capacityUsed: {
        tpm: string;
        rpm: string;
      };
    }> {
      this.updateAllMetrics();
      //eslint-disable-next-line
      const stats: Record<string, any> = {};
      
      Object.keys(this.MODELS).forEach(modelName => {
        const model = this.MODELS[modelName];
        const metrics = this.metrics[modelName];
        const status = this.status[modelName];
        
        stats[modelName] = {
          model,
          metrics,
          status,
          capacityUsed: {
            tpm: `${metrics.tokensInCurrentMinute}/${model.tpmLimit} (${Math.round(status.currentLoad * 100)}%)`,
            rpm: `${metrics.requestsInCurrentMinute}/${model.rpmLimit}`
          }
        };
      });
      
      return stats;
    }
  
    /**
     * üìä OBTER CAPACIDADE TOTAL DISPON√çVEL
     */
    static getTotalCapacity(): {
      totalTPM: number;
      availableTPM: number;
      totalRPM: number;
      availableRPM: number;
      activeProviders: number;
    } {
      this.updateAllMetrics();
      
      let totalTPM = 0;
      let availableTPM = 0;
      let totalRPM = 0;
      let availableRPM = 0;
      let activeProviders = 0;
      
      Object.keys(this.MODELS).forEach(modelName => {
        const model = this.MODELS[modelName];
        const metrics = this.metrics[modelName];
        const status = this.status[modelName];
        
        totalTPM += model.tpmLimit;
        totalRPM += model.rpmLimit;
        
        if (status.isAvailable) {
          activeProviders++;
          availableTPM += (model.tpmLimit - metrics.tokensInCurrentMinute);
          availableRPM += (model.rpmLimit - metrics.requestsInCurrentMinute);
        }
      });
      
      return {
        totalTPM,
        availableTPM: Math.max(0, availableTPM),
        totalRPM,
        availableRPM: Math.max(0, availableRPM),
        activeProviders
      };
    }
  
    /**
     * üîÑ RESET MANUAL DAS M√âTRICAS (para debug/admin)
     */
    static resetMetrics(): void {
      Object.keys(this.MODELS).forEach(modelName => {
        this.metrics[modelName] = {
          requestsInCurrentMinute: 0,
          tokensInCurrentMinute: 0,
          lastRequestTime: 0,
          minuteWindowStart: Date.now(),
          totalRequests: 0,
          totalTokens: 0,
          errorCount: 0,
          averageResponseTime: 0
        };
        
        this.status[modelName] = {
          isAvailable: true,
          nextAvailableTime: 0,
          currentLoad: 0,
          consecutiveErrors: 0
        };
      });
      
      console.log('‚úÖ M√©tricas do MultiProviderService resetadas');
    }
  }